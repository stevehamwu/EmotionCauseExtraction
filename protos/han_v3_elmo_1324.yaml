_data :
  data_root: /data/wujipeng/ec/data/ltp_static/
  class: utils.dataset.elmo.ELMoECDataset
  settings:
    elmo_embed_file: '/data/wujipeng/ec/data/embedding/elmo_sent_embedding1024d.pkl'
    kw_embed_file: '/data/wujipeng/ec/data/embedding/elmo_kw_embedding1024d.pkl'
    collate_fn: avg_collate_fn

_model :
  model_root : /data/wujipeng/ec/model/
  name : han_v3_elmo_1324
  class: models.han.han.HierarchicalAttentionNetworkV3ELMo
  settings :
    sentence_model:
      class: SentenceWithPosition
      args:
        batch_size: 16
        word_rnn_size: 512
        rnn_size: 1024
        rnn_layers: 2
        pos_size: 103
        pos_embedding_dim: 300
        pos_embedding_file: /data/wujipeng/ec/data/embedding/pos_embedding.pkl
        dropout: 0.5
        fix_pos: True
    elmo_dim: 1024
    num_classes: 2
    dropout: 0.3
    fix_embed: False

_train :
  debug_level: 1 # 0: 用test数据 1: 重新分配数据
  gpu: 2
  criterion :
    class : torch.nn.CrossEntropyLoss
    args :
      reduction : mean
      ignore_index: -100
  clip_grad_norm : True
  grad_clip_value : 0.5
  optimizer :
    class : torch.optim.Adam
    args :
      lr : 3.e-4
      betas: [0.9, 0.999]
      eps: 1.e-8
  pretrain : False
  max_epoch : 100
  batch_size : 16
  early_stopping_rounds : 10
  disp_freq : 15
  eval_freq : 119
  save_freq : 119
  finetune: False
  metrics:
    class: metrics.ec.ec.ECMetrics
    args:
      ignore_index: -100
  statistics:
    class: statistics.ec.ec.ECStatistics

_eval :
  eval_root: /data/wujipeng/ec/eval/
  debug_level: 1 # 0: 用test数据 1: 重新分配数据
  batch_size : 16
  metrics:
    class: metrics.ec.ec.ECMetrics
    args:
      ignore_index: -100
  criterion:
    class: torch.nn.CrossEntropyLoss
    args:
      reduction: mean
      ignore_index: -100
  statistics:
    class: statistics.ec.ec.ECStatistics