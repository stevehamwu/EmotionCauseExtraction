_data :
  data_root: /data/wujipeng/ec/data/ltp_static/
  class: utils.dataset.memnet.MECDataset
  settings:
    vocab_root: /data/wujipeng/ec/data/raw_data/memnet_ltp_vocab.txt
    batch_size: 16

_model :
  model_root : /data/wujipeng/ec/model/
  name : memnet
  class: models.memnet.memnet.MemN2N
  settings :
    batch_size: 16
    vocab_size: 19909
    memory_size: 40
    sentence_size: 3
    num_classes: 2
    embedding_dim: 20
    hops: 3
    dropout: 0.1
    fix_embed: False

_train :
  debug_level: 1 # 0: 用test数据 1: 重新分配数据
  gpu: 2
  criterion :
    class : torch.nn.CrossEntropyLoss
    args :
      reduction: sum
      ignore_index: -100
  clip_grad_norm : False
  grad_clip_value : 40.0
  optimizer :
    class : torch.optim.Adam
    args :
      lr : 2.e-4
#      betas: [0.9, 0.999]
#      eps: 1.e-8
  pretrain : True
  pretrained_file : /data/wujipeng/ec/data/embedding/memnet_embedding20d.pkl
  max_epoch : 100
  batch_size : 16
  early_stopping_rounds : 10
#  decay_round: 3
#  decay_rate: 0.5
  disp_freq : 150
  eval_freq : 1755
  save_freq : 1755
  finetune: False
  ranking: True
  metrics:
    class: metrics.ec.memnet.MECMetrics
    args:
      ignore_index: -100
  statistics:
    class: statistics.ec.memnet.MECStatistics

_eval :
  eval_root: /data/wujipeng/ec/eval/
  debug_level: 1 # 0: 用test数据 1: 重新分配数据
  batch_size : 16
  metrics:
    class: metrics.ec.ec.ECMetrics
    args:
      ignore_index: -100
  criterion:
    class: torch.nn.CrossEntropyLoss
    args:
      reduction: mean
      ignore_index: -100
  statistics:
    class: statistics.ec.ec.ECStatistics