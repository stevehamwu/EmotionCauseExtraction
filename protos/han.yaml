_data :
  data_root: /data10T/data/wujipeng/ec/data/static/
  class: utils.dataset.ec.ECDataset
  settings:
    vocab_root: /data10T/data/wujipeng/ec/data/raw_data
    batch_size: 16

_model :
  model_root : /data10T/data/wujipeng/ec/model
  class: models.han.han.HierarchicalAttentionNetwork
  name : han
  settings :
    sentence_model:
      class: SentenceAttention
      args:
        batch_size: 16
        rnn_size: 100
        rnn_layers: 1
        dropout: 0.3
    batch_size: 16
    vocab_size: 23071
    num_classes: 2
    sequence_length: 41
    embedding_dim: 300
    word_rnn_size: 100
    word_rnn_layers: 1
    dropout: 0.3
    fix_embed: False

_train :
  debug_level: 1
  criterion :
    class : torch.nn.CrossEntropyLoss
    args :
      reduction : mean
      ignore_index: -100
  clip_grad_norm : False
  grad_clip_value : 1
  optimizer :
    class : torch.optim.Adam
    args :
      lr : 1.e-3
      betas: [0.9, 0.999]
      eps: 1.e-8
  pretrain : True
  pretrained_file : /data10T/data/wujipeng/ec/data/embedding/sogou_embedding300d.pkl
  max_epoch : 100
  batch_size : 16
  early_stopping_rounds : 5
  disp_freq : 15
  eval_freq : 119
  save_freq : 119
  finetune: True
  metrics:
    class: metrics.ec.ec.ECMetrics
    args:
      ignore_index: -100
  statistics:
    class: statistics.ec.ec.ECStatistics

_eval :
  batch_size : 16
  metrics :
    class : metrics.ec.han.ECAMetrics
    settings :
      average : binary
      ignore_index: -100
  statistics :
    class : statistics.ec.ec.ECAStatistics
    settings :
      real_file : /home/wujipeng/data/ec/data/real.npz
